\section*{General}%
\label{sec:section_name}

head - prints the first 10 lines of a file

chmod - change mode of files
chown - change ownership
\begin{verbatim}
	sudo chown -R $USER:$USER $HOME
	#will change ownership recursively for a folder
\end{verbatim}

don't forget to launch xserver on windows! otherwise apps will load slow as fuck

\section{targz}%
\label{sec:targz}

shit for linux comes tarballed and gzed so here's a quick way to untar that shit, the following flags: -x to extract (or -c to compress if you wanna reverse), -v for verbose output, -z for gz, -f for file/folder output name:
\begin{verbatim}
	$tar -xzvf archive.tar.gz ~/customname
\end{verbatim}
\section*{grep}%
\label{sec:grep}
grep is a simple but powerful text search/operation command (global regex print) that is just superfast and shit, useful especially when used in conjuction with piped operation (see piping~\ref{sec:piping})
some useful flags include:
\begin{itemize}
	\item v inverts matechs
	\item i ignores case sensitivity
	\item r recursive search
\end{itemize}
text
\section{piping}
\label{sec:piping}

say you got a bunch of  folder with files that contain shitloads of strings, and you want to search for all lines containing the word 'word'. best thing to do would be to grep it with -Hnir where H is filename, n line number, i is case sensitivity and r recursivity in case of subfolders. this will spit out output into console, so if you wanna work with this as a text file then you could pipe it into vim with the - flag which takes buffer output:
\begin{verbatim}
	grep -Hnri "searchthing" | vim -
\end{verbatim}

\section{xargs}%
\label{sec:xargs}

xargs takes multiple lines as input and runs a command on all of them one by one. simple example useful for piping through vim - run a shell command echo (sh -c 'echo {}') on all the lines of a concrete file (-a filename), one line at a time (-n1)
\begin{verbatim}
	$xargs -a filename -n1 -I{} sh -c 'echo {}'
\end{verbatim}
\section{curl}%
\label{sec:curl}

curl is Client URL, uhh...a terminal thing to do shit with urls like download, scrape and god knows what else, anyway, we care about downloading so
\subsection{downloading}%
\label{sub:downloading}

actually pretty straightforward, just gotta remember to slap it with a few flags, namely -o to output into a file (instead of just a stdout), -L to follow redirects
\begin{verbatim}
	$curl URL/stupiddownloaditemname -o customname -L
\end{verbatim}
\section{adminning}%
\label{sec:adminning}

\subsubsection{logging logins}%
\label{ssub:logging_logins}

This is a simple bash script that will log any login attempts (using entries of /var/log/auth.log, useful to monitor remote systems etc.)
create a file called 'attacker':
\begin{verbatim}
	#!/bin/bash
	#
	#       attacker - prints out the last failed login attempt
	#
	echo  "The last failed login attempt came from IP address:"
	grep -i "disconnected from" /var/log/auth.log|tail -1| cut -d: -f4| cut -f7 -d" "
\end{verbatim}
don't forget to make it executable and leave in the bin dir:
\begin{verbatim}
	sudo chmod +x attacker
	sudo mv attacker /usr/local/bin/attacker
\end{verbatim}

also an advanced version:
\begin{verbatim}
	#
	##     topattack - list the most persistent attackers
	#
	if [ -z "$1" ]; then
	echo -e "\nUsage: `basename $0` <num> - Lists the top <num> attackers by IP"
	exit 0
	fi
	echo " "
	echo "Persistant recent attackers"
	echo " "
	echo "Attempts     IP "
	echo "-----------------------"
	grep "Disconnected from authenticating user root" /var/log/auth.log|cut -d: -f 4 | cut -d" " -f7|sort |uniq -c |sort -nr |head -$1
\end{verbatim}
